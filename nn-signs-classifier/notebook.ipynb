{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratorium Automatyka Pojazdowa: Klasyfikator znaków drogowych\n",
    "\n",
    "## Część 1: Klasyfikacja\n",
    "\n",
    "Problem do rozwiązania w ramach tego laboratorium jest zadaniem klasyfikacji: przypisania danym wejściowym - w tym wypadku zdjęciom znaków - etykiet - w tym wypadku: nazw typów znaków.\n",
    "\n",
    "Do rozwiązania problemu należy przygotować konwolucyjną sieć neuronową, która będzie rozwiązywała to zagadnienie.\n",
    "\n",
    "Podstawowa struktura konwolucyjnej sieci neuronowej to:\n",
    "- grupa / grupy powtarzanych naprzemiennie warstw `Conv2D` oraz `MaxPooling2D`, które \"tworzą\" rosnącą (w wymiarze głębi) grupę tzw. map cech (feature maps; wizualizację tego procesu przedstawiono w [przejrzysty sposób w tym miejscu](https://what-when-how.com/wp-content/uploads/2012/07/tmp725d63_thumb.png))\n",
    "- warstwa flatten (która \"spłaszcza\" wszystkie piksele z map cech do jednowymiarowego wektora)\n",
    "- warstwa bądź warstwy gęsto połączone przetwarzające spłaszczone mapy cech\n",
    "- warstwa wyjściowa będącą również warstwą gęsto połączoną, tyle że z funkcją aktywacji [softmax](https://en.wikipedia.org/wiki/Softmax_function) o liczbie neuronów równej liczbie klas - co sprawia, że każdy z neuronów w tej warstwie odpowiada jednej z klas i ma przyjmuje wartość będącą prawdopodobieństwem, że dane wejściowe odpowiadają danej klasie; f. aktywacji softmax w tej warstwie zapewnia spełnienie warunku, aby suma wspomnianych prawdopodobieństw była $\\leqslant 1$\n",
    "\n",
    "Jako funkcję straty optymalizatora należy wykorzystać (jest to już zaimplementowane) [SCCE (Sparse Categorical Cross-Entropy)](https://www.tensorflow.org/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy), czyli binarna entropia krzyżowa kodująca etykiety w postaci rosnącej liczby przyporządkowanej każdej z klas - sprawia to, że w ostatniej warstwie funkcją aktywacji będzie [sygmoida](https://en.wikipedia.org/wiki/Sigmoid_function).\n",
    "\n",
    "Należy zatem:\n",
    "- uzupełnić notatnik, aby był funkcjonalny, sieć trenowała się i realizowała opisane zadanie\n",
    "- wykonać eksperymenty, zmieniając parametry zgodnie z tabelką na dole tego notatnika\n",
    "- z każdego eksperymentu zanotować w notatniku wyniki (m. in. accuracy oraz ilość iteracji, po której nastąpiła zbieżność podczas trenowania) oraz zapisać obserwacje\n",
    "- zapisywać do katalogu `img/` po wytrenowaniu i przetestowaniu każdej z finalnie dobranych struktur sieci neuronowej, wykresy:\n",
    "    - struktury sieci - do pliku `modelX.png`: `model1.png`, `model2.png`, ...\n",
    "    - krzywej skuteczności sieci i straty optymalizatora (jeden plik - są to subploty) w pliku o nazwie wskazanej w tabeli - do pliku `fittingX.png`: `fitting1.png`, `fitting2.png`, ...\n",
    "    \n",
    "    Zapisywanie wykresów z notatnika Jupyter jest bardzo proste, co zostało przedstawione poniżej:\n",
    "    \n",
    "    <img src=\"img/tutorial-saving-plot-to-file.png\" width=\"80%\">\n",
    "\n",
    "    Należy pamiętać o zapisywaniu tych wykresów oraz poprawnym nazewnictwie - dzięki temu nie będzie konieczne dodatkowe wprowadzanie zmian w nazwach plików w tabelce z rezultatami na dole notatnika.\n",
    "\n",
    "- zanotować w tablece na dole notatnika wnioski podsumowujące wpływ parametrów na zachowanie, skuteczność sieci i czas zbieżności jej trenowania\n",
    "\n",
    "\n",
    "\n",
    "W tym notatniku Jupyter Notebook przygotowany został szablon, w którym miejsca oznaczone komentarzem `# TODO` należy zastąpić właściwym kodem. Niektóre fragmenty kody w okolicy takich komentarzy zastąpiono Ellipsis (`...`), które również należy usunąć przed uzupełnianiem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zaimportowanie wykorzystywanych pakietów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image as JupyterImage\n",
    "from typing import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sprawdzenie dostępności kart (oraz oprogramowania) GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available GPUs:\")\n",
    "for dev in tf.config.list_physical_devices('GPU'):\n",
    "    details = tf.config.experimental.get_device_details(dev)\n",
    "\n",
    "    devName = details.get('device_name', '?')\n",
    "    computeCapabilityTup = details.get('compute_capability', '?')\n",
    "\n",
    "    print(f\"{dev.name} -> {devName}, compute capability {computeCapabilityTup[0]}.{computeCapabilityTup[1]}\")\n",
    "else:\n",
    "    print(\"No GPUs detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pobranie oraz rozpakowanie zbioru danych\n",
    "\n",
    "\n",
    "Do tego zadania wykorzystany został zbiór danych [chriskjm/polish-traffic-signs-dataset](https://www.kaggle.com/datasets/chriskjm/polish-traffic-signs-dataset), który zawiera w sobie:\n",
    "- przycięte zdjęcia RGB polskich znaków drogowych o rozmiarach `256x256x3` ([`../data/classification/<nazwa klasy>/0...n.jpg`](../data/classification/)) do problemu klasyfikacji,\n",
    "- nieprzycięte zdjęcia RGB polskich znaków drogowych do problemu lokalizacji:\n",
    "    - ([`../data/detection/imgs/0...n.jpg`](../data/detection/imgs)) - zdjęcia nieprzyciętych znaków\n",
    "    - ([`../data/detection/labels/0...n.txt`](../data/detection/labels)) - etykiety zdjęć: klasy wraz ze współrzędnymi bounding boxów (prostokątów opisanych na poszukiwanym obiekcie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"../data/polish-traffic-signs-dataset.zip\"):\n",
    "    !pip install kaggle\n",
    "    !kaggle datasets download -d chriskjm/polish-traffic-signs-dataset\n",
    "    !mv polish-traffic-signs-dataset.zip ../data/polish-traffic-signs-dataset.zip\n",
    "else:\n",
    "    print(\"Dataset zip present on disk\")\n",
    "\n",
    "if not os.path.exists(\"../data/classification\") or not os.path.exists(\"../data/detection\"):\n",
    "    !unzip -q ../data/polish-traffic-signs-dataset -d ../data/\n",
    "else:\n",
    "    print(\"Extracted dataset present on disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Załadowanie danych ze zbioru danych\n",
    "\n",
    "Z pomocą funkcji `tf.keras.utils.image_dataset_from_directory` możliwe jest załadowanie danych do nowej instancji klasy `tf.data.Dataset`, która w efektywny sposób pozwala ładować dane w tzw. wsadach (batchach) za pomocą iterowalnego generatora, co pozwala na optymalizację użycia pamięci, gdyż cały dataset (który może być bardzo duży) nie jest ładowany z dysku, a w zamian pojedyczne jego partie są ładowane w chwili, gdy próbuje się uzyskać do nich dostęp.\n",
    "\n",
    "Metoda przyjmuje dodatkowo parametry pozwalające skonfigurować sposób ładowania danych, m. in.:\n",
    "- `labels` - `inferred` powoduje załadowanie etykiety danej próbki z nazwy zawierającego ją folderu\n",
    "- `color_mode` - pozwala na np. binaryzację obrazów; w naszym przypadku będą one załadowane jako RGB - z 3 kanałami\n",
    "- `batch_size` - kontroluje rozmiar wsadu - dataset można iterować po wsadach\n",
    "- `image_size` - pozwala na prostą zmianę rozmiaru\n",
    "- `shuffle` - losowo przetasowywuje kolejność próbek\n",
    "- `validation_split` - pozwala na podział próbek na zbiór treningowy i walidacyjny (w tym przypadku jest on wykorzystywany jako testowy) - ten parametr oznacza znormalizowany % próbek, który trafi do zbioru walidacyjnego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = ... # TODO: no. of images in a single batch; start experimenting with 32\n",
    "IMAGE_SIZE = ... # px, image size; set to 256\n",
    "\n",
    "train_dataset: tf.data.Dataset\n",
    "train_dataset: tf.data.Dataset\n",
    "train_dataset, test_dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"../data/classification\",\n",
    "    labels='inferred',\n",
    "    label_mode='int', # for SCCE loss\n",
    "    color_mode='rgb',\n",
    "    batch_size=BATCH_SIZE,\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    shuffle=True,\n",
    "    validation_split=..., # TODO: 80% train, 20% test - proszę sprawdzić w dokumentacji znaczenie parametru\n",
    "    subset=\"both\",\n",
    "    seed=100\n",
    ")\n",
    "\n",
    "classNames = train_dataset.class_names\n",
    "classesCount = len(classNames)\n",
    "print(f\"Loaded {classesCount} classes: {', '.join(classNames)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../models/classifierClassNames.pickle\", \"wb+\") as f:\n",
    "    pickle.dump(classNames, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poniższa komórka wyświetla 25 losowych znaków z treningowego zbioru danych wraz etykietami:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIEW_COLS = 5\n",
    "PREVIEW_ROWS = 5\n",
    "FIG_UNIT_SIZE = 2\n",
    "\n",
    "fig, axs = plt.subplots(nrows=PREVIEW_ROWS, ncols=PREVIEW_COLS, figsize=(PREVIEW_COLS * FIG_UNIT_SIZE, PREVIEW_ROWS * FIG_UNIT_SIZE))\n",
    "print(f\"Displaying {PREVIEW_COLS * PREVIEW_ROWS} random train dataset samples\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# create an iterator to a copy of the dataset unbatched, i.e., iterated not in batches of shape (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3), but (IMAGE_SIZE, IMAGE_SIZE, 3) - single RGB 256x256 images\n",
    "samplesIter = iter(train_dataset.unbatch())\n",
    "\n",
    "for i in range(PREVIEW_ROWS):\n",
    "    for j in range(PREVIEW_COLS):\n",
    "        sample = next(samplesIter)\n",
    "\n",
    "        image, classIndex = sample\n",
    "        classIndex = classIndex.numpy() # tf.Tensor -> np.ndarray\n",
    "        classLabel = classNames[classIndex]\n",
    "        \n",
    "        axs[j][i].imshow(image.numpy().astype(np.uint8)) # tf.Tensor -> np.ndarray, np.ndarray as uint8 ([0, 255])\n",
    "        axs[j][i].set_title(classLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stworzenie struktury modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3), name=\"input\"),\n",
    "    # TODO: proszę dodać dwukrotnie:\n",
    "    # - najpierw warstwę konwolucyjną o o 30 filtrach i rozmiarze kernela 3x3 oraz f. aktywacji relu - https://www.tensorflow.org/api_docs/python/tf/keras/layers/Conv2D\n",
    "    # - następnie warstwę max pooling 2D o pool size 2x2 - https://www.tensorflow.org/api_docs/python/tf/keras/layers/MaxPool2D\n",
    "    tf.keras.layers.Flatten(),\n",
    "    # TODO: proszę dodać warstwę Dense o 512 neuronach i funkcji aktywacji relu - https://www.tensorflow.org/api_docs/python/tf/keras/layers/Dense\n",
    "    tf.keras.layers.Dense(classesCount, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(\n",
    "        learning_rate=0.001\n",
    "    ),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "model.summary()\n",
    "\n",
    "tf.keras.utils.plot_model(model, to_file=\"model.png\", show_shapes=True, show_layer_activations=True, show_trainable=True, show_dtype=True, show_layer_names=True)\n",
    "JupyterImage(filename='model.png', width=\"500px\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trenowanie modelu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 30\n",
    "history = model.fit(train_dataset, epochs=EPOCHS, validation_data=test_dataset, validation_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_dict = history.history\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "axes = axes.ravel()\n",
    "keys = list(history_dict.keys())\n",
    "for k in keys:\n",
    "  ax = axes[0 if k.endswith(\"loss\") else 1]\n",
    "\n",
    "  ax.plot(history_dict[k], label=k)\n",
    "  ax.grid()\n",
    "\n",
    "for ax in axes:\n",
    "  ax.legend()\n",
    "\n",
    "axes[0].set_title(\"Optimizer loss\")\n",
    "axes[1].set_title(\"Model accuracy\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Model test loss: {test_loss :.2f}, test accuracy: {test_acc * 100 :.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klasyfikacja losowych próbek - wizualizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREVIEW_COLS = 5\n",
    "PREVIEW_ROWS = 5\n",
    "FIG_UNIT_SIZE_W, FIG_UNIT_SIZE_H = 4, 4.5\n",
    "\n",
    "fig, axs = plt.subplots(nrows=PREVIEW_ROWS, ncols=PREVIEW_COLS, figsize=(PREVIEW_ROWS * FIG_UNIT_SIZE_H, PREVIEW_COLS * FIG_UNIT_SIZE_W))\n",
    "print(f\"Classifying {PREVIEW_COLS * PREVIEW_ROWS} random train dataset samples\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# create an iterator to a copy of the dataset unbatched, i.e., iterated not in batches of shape (BATCH_SIZE, IMAGE_SIZE, IMAGE_SIZE, 3), but (IMAGE_SIZE, IMAGE_SIZE, 3) - single RGB 256x256 images\n",
    "samplesIter = iter(train_dataset.unbatch())\n",
    "\n",
    "for i in range(PREVIEW_ROWS):\n",
    "    for j in range(PREVIEW_COLS):\n",
    "        sample = next(samplesIter)\n",
    "\n",
    "        image, classIndex = sample\n",
    "        classIndex = classIndex.numpy() # tf.Tensor -> np.ndarray\n",
    "        classLabel = classNames[classIndex]\n",
    "\n",
    "        predictions = model.predict(image.numpy().reshape(1, IMAGE_SIZE, IMAGE_SIZE, 3))[0]\n",
    "        classPredictionIndex = np.argmax(predictions)\n",
    "        classPredictionProbability = predictions[classPredictionIndex]\n",
    "        classPredictionLabel = classNames[classPredictionIndex]\n",
    "        \n",
    "        axs[j][i].imshow(image.numpy().astype(np.uint8)) # tf.Tensor -> np.ndarray, np.ndarray as uint8 ([0, 255])\n",
    "        axs[j][i].set_title(f\"Pred: {classPredictionLabel}, real: {classLabel}, prob: {classPredictionProbability * 100 :.1f}% ({'OK' if classPredictionLabel == classLabel else 'FAILURE'})\")\n",
    "        axs[j][i].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wyeksportowanie grafu inferencji - zoptymalizowanego formatu modelu wraz z wyuczonymi wagami, na którym można efektywnie przeprowadzać inferencję - tj. predykcję dla dowolnych danych wejściowych\n",
    "\n",
    "model.save('../models/classifier.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wyniki, wnioski i obserwacje\n",
    "\n",
    "\n",
    "|             Architektura sieci              | Czas zbieżności <br/> uczenia [epochs] | Skuteczność na zbiorze<br/>testowym po osiągnięciu<br/>zbieżności (accuracy) [%] | Czas do wystąpienia<br/>overfittingu [epochs] |           Wykres krzywych uczenia             |\n",
    "| :-----------------------------------------: | :------------------------------------: | :------------------------------------------------------------------------------: | :-------------------------------------------: | :------------------------------------------:  |\n",
    "| <img src=\"./img/model1.png?a=1\" width=\"400px\">  |                    X                   |                                         X                                        |                     X                         | <img src=\"./img/fitting1.png?a=1\" width=\"700px\"> |\n",
    "| <img src=\"./img/model2.png\" width=\"400px\">  |                    X                   |                                         X                                        |                     X                         | <img src=\"./img/fitting2.png\" width=\"700px\"> |\n",
    "| <img src=\"./img/model3.png\" width=\"400px\">  |                    X                   |                                         X                                        |                     X                         | <img src=\"./img/fitting3.png\" width=\"700px\"> |\n",
    "| <img src=\"./img/model4.png\" width=\"400px\">  |                    X                   |                                         X                                        |                     X                         | <img src=\"./img/fitting4.png\" width=\"700px\"> |\n",
    "| <img src=\"./img/model5.png\" width=\"400px\">  |                    X                   |                                         X                                        |                     X                         | <img src=\"./img/fitting5.png\" width=\"700px\"> |\n",
    "| <img src=\"./img/model6.png\" width=\"400px\">  |                    X                   |                                         X                                        |                     X                         | <img src=\"./img/fitting6.png\" width=\"700px\"> |\n",
    "\n",
    "Wnioski:\n",
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
